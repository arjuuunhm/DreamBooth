{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ae024d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: diffusers in /home/ahm247/.local/lib/python3.8/site-packages (0.27.2)\n",
      "Requirement already satisfied: importlib-metadata in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from diffusers) (3.10.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from diffusers) (2021.4.4)\n",
      "Requirement already satisfied: Pillow in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from diffusers) (8.2.0)\n",
      "Requirement already satisfied: requests in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from diffusers) (2.25.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ahm247/.local/lib/python3.8/site-packages (from diffusers) (0.4.2)\n",
      "Requirement already satisfied: filelock in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from diffusers) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.2 in /home/ahm247/.local/lib/python3.8/site-packages (from diffusers) (0.21.4)\n",
      "Requirement already satisfied: numpy in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from diffusers) (1.20.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ahm247/.local/lib/python3.8/site-packages (from huggingface-hub>=0.20.2->diffusers) (2024.3.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from huggingface-hub>=0.20.2->diffusers) (4.61.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ahm247/.local/lib/python3.8/site-packages (from huggingface-hub>=0.20.2->diffusers) (4.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from huggingface-hub>=0.20.2->diffusers) (20.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from huggingface-hub>=0.20.2->diffusers) (5.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from packaging>=20.9->huggingface-hub>=0.20.2->diffusers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from importlib-metadata->diffusers) (3.4.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from requests->diffusers) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from requests->diffusers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from requests->diffusers) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from requests->diffusers) (2.10)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: invisible_watermark in /home/ahm247/.local/lib/python3.8/site-packages (0.2.0)\n",
      "Requirement already satisfied: transformers in /home/ahm247/.local/lib/python3.8/site-packages (4.40.1)\n",
      "Requirement already satisfied: accelerate in /home/ahm247/.local/lib/python3.8/site-packages (0.29.3)\n",
      "Requirement already satisfied: safetensors in /home/ahm247/.local/lib/python3.8/site-packages (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from invisible_watermark) (1.20.2)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /home/ahm247/.local/lib/python3.8/site-packages (from invisible_watermark) (4.9.0.80)\n",
      "Requirement already satisfied: Pillow>=6.0.0 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from invisible_watermark) (8.2.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from invisible_watermark) (1.1.1)\n",
      "Requirement already satisfied: torch in /home/ahm247/.local/lib/python3.8/site-packages (from invisible_watermark) (2.2.1)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/ahm247/.local/lib/python3.8/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: filelock in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from transformers) (4.61.1)\n",
      "Requirement already satisfied: requests in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/ahm247/.local/lib/python3.8/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ahm247/.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ahm247/.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: psutil in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from accelerate) (5.8.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ahm247/.local/lib/python3.8/site-packages (from torch->invisible_watermark) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ahm247/.local/lib/python3.8/site-packages (from torch->invisible_watermark) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from torch->invisible_watermark) (3.0.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ahm247/.local/lib/python3.8/site-packages (from torch->invisible_watermark) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ahm247/.local/lib/python3.8/site-packages (from torch->invisible_watermark) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/ahm247/.local/lib/python3.8/site-packages (from torch->invisible_watermark) (2.19.3)\n",
      "Requirement already satisfied: sympy in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from torch->invisible_watermark) (1.8)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/ahm247/.local/lib/python3.8/site-packages (from torch->invisible_watermark) (2.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ahm247/.local/lib/python3.8/site-packages (from torch->invisible_watermark) (12.1.105)\n",
      "Requirement already satisfied: networkx in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from torch->invisible_watermark) (2.5)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ahm247/.local/lib/python3.8/site-packages (from torch->invisible_watermark) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ahm247/.local/lib/python3.8/site-packages (from torch->invisible_watermark) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ahm247/.local/lib/python3.8/site-packages (from torch->invisible_watermark) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ahm247/.local/lib/python3.8/site-packages (from torch->invisible_watermark) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ahm247/.local/lib/python3.8/site-packages (from torch->invisible_watermark) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ahm247/.local/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->invisible_watermark) (12.4.99)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from jinja2->torch->invisible_watermark) (2.0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: decorator>=4.3.0 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from networkx->torch->invisible_watermark) (5.0.9)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: mpmath>=0.19 in /share/apps/anaconda3/2021.05/lib/python3.8/site-packages (from sympy->torch->invisible_watermark) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install diffusers --upgrade\n",
    "!pip install invisible_watermark transformers accelerate safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d13950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline, StableDiffusionPipeline\n",
    "import transformers\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import RandAugment\n",
    "from IPython.core.debugger import set_trace\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f169af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the model to use off huggingface\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "\n",
    "# Path to directory containing images of the subject we want to use dreambooth on\n",
    "dataset_path = '/home/ahm247/dreambooth/dataset/dog6'\n",
    "\n",
    "# Path to our 200 photos of our prior found online. For another class generate the data\n",
    "classes_path = '/home/ahm247/dreambooth/class-images'\n",
    "\n",
    "# Prior and fine-tuning prompts\n",
    "prior_prompt = 'A dog'\n",
    "id_prompt = 'A sks dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e01a326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset class for prior images\n",
    "class CustomImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, directory, transform=None):\n",
    "        self.directory = directory \n",
    "        self.transform = transform\n",
    "        self.image_paths = [os.path.join(directory, filename) for filename in os.listdir(directory)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d57fdec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ead3da588b48cca1b44c0e4272028d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StableDiffusionPipeline {\n",
       "  \"_class_name\": \"StableDiffusionPipeline\",\n",
       "  \"_diffusers_version\": \"0.27.2\",\n",
       "  \"_name_or_path\": \"CompVis/stable-diffusion-v1-4\",\n",
       "  \"feature_extractor\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPImageProcessor\"\n",
       "  ],\n",
       "  \"image_encoder\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"requires_safety_checker\": true,\n",
       "  \"safety_checker\": [\n",
       "    \"stable_diffusion\",\n",
       "    \"StableDiffusionSafetyChecker\"\n",
       "  ],\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"PNDMScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"unet\": [\n",
       "    \"diffusers\",\n",
       "    \"UNet2DConditionModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_pipe = StableDiffusionPipeline.from_pretrained(model_id, \n",
    "                                                torch_dtype=torch.float16,\n",
    "                                                use_safetensors=True,\n",
    "                                                variant=\"fp16\")\n",
    "finetuned_pipe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a6f41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_token = finetuned_pipe.tokenizer([prior_prompt])\n",
    "id_token = finetuned_pipe.tokenizer([id_prompt])\n",
    "\n",
    "# Setting up the datasets/dataloaders\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512,512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "prior_dataset = CustomImageDataset(directory=classes_path, transform=transform)\n",
    "id_dataset = CustomImageDataset(directory=dataset_path, transform=transform)\n",
    "prior_dataloader = torch.utils.data.DataLoader(prior_dataset, batch_size=1, shuffle=True)\n",
    "id_dataloader = torch.utils.data.DataLoader(id_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf949491",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.cuda.FloatTensor{[1, 2]}, size=[1]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-baa089601d3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mnoisy_id_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid_latent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_latent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mdenoised_prior_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinetuned_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_prior_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimestep_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprior_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mdenoised_id_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinetuned_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_id_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimestep_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/diffusers/models/unets/unet_2d_condition.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sample, timestep, encoder_hidden_states, class_labels, timestep_cond, attention_mask, cross_attention_kwargs, added_cond_kwargs, down_block_additional_residuals, mid_block_additional_residual, down_intrablock_additional_residuals, encoder_attention_mask, return_dict)\u001b[0m\n\u001b[1;32m   1139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;31m# 1. time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m         \u001b[0mt_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_time_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestep_cond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m         \u001b[0maug_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/diffusers/models/unets/unet_2d_condition.py\u001b[0m in \u001b[0;36mget_time_embed\u001b[0;34m(self, sample, timestep)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0;31m# broadcast to batch dimension in a way that's compatible with ONNX/Core ML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         \u001b[0mtimesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mt_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expand(torch.cuda.FloatTensor{[1, 2]}, size=[1]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "finetuned_pipe.unet.train()\n",
    "optimizer = optim.AdamW(finetuned_pipe.unet.parameters(), \n",
    "                        lr=5e-6,\n",
    "                        betas=(0.9,0.999),\n",
    "                        weight_decay=1e-2,\n",
    "                        eps=1e-08)\n",
    "mse_loss = nn.MSELoss()\n",
    "max_timesteps = scheduler.num_train_timesteps\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    for (prior_images, id_images) in zip(prior_dataloader, id_dataloader):\n",
    "        prior_images = prior_images.to(torch.float16).to(device)\n",
    "        id_images = id_images.to(torch.float16).to(device)\n",
    "        \n",
    "        for timestep in range(scheduler.num_train_timesteps):\n",
    "            \n",
    "            timestep_idx = torch.tensor([timestep], device=device)\n",
    "            timestep_embedding = timestep_embedding_layer(timestep_idx)\n",
    "            \n",
    "            prior_latent = finetuned_pipe.vae.encode(prior_images).latent_dist.sample()\n",
    "            prior_latent *= 0.18215\n",
    "            noisy_prior_latent = prior_latent + torch.randn_like(prior_latent)\n",
    "\n",
    "            id_latent = finetuned_pipe.vae.encode(id_images).latent_dist.sample()\n",
    "            id_latent *= 0.18215\n",
    "            noisy_id_latent = id_latent + torch.randn_like(id_latent)\n",
    "\n",
    "            denoised_prior_latent = finetuned_pipe.unet(noisy_prior_latent, timestep=timestep_embedding, encoder_hidden_states=prior_token)\n",
    "            denoised_id_latent = finetuned_pipe.unet(noisy_id_latent, timestep=timestep_embedding, encoder_hidden_states=id_token) \n",
    "\n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Calculate loss\n",
    "            loss_id = mse_loss(id_token, input_images)\n",
    "            loss_pr = mse_loss(noise_image, prior_images)\n",
    "            loss = loss_id + loss_pr\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e994eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3227e8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
